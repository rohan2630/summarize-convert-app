--> The role of ai in advancing and mitigating the effects of disinformation has serious implications.

--> An un-deliberated adoption of such applications can plunge the world into an ai dystopia.

--> Bots that amplify such content at scale can enable scalable, efficient and widespread propaganda.

--> A lack of a robust framework to detect and penalize creation and dissemination of manipulated content.

--> Examples of synthetic media include: 1) deepfakes; 2) artificial images; 3) synthetic audio and speech.

--> Synthetic audio can pose a serious threat to human security and the job market.

--> Despite its capabilities in creating automated content, it can pose serious threats.

--> The security threat of synthetic audio is high, according to a new report.

--> Ai systems can recognize patterns, predict behaviour of users, target specific user base with specific content, and artificially amplify and promote content through bots.

--> Advances in nlp have allowed evolution of ai systems to be able to recognize, analyse, interpret and develop emotionally relevant content.

--> However, there is a critical methodological hurdle vis-a-vis governance of such emerging technologies.

--> All machine learning models are ai models but the opposite is not necessarily true.

--> Some of the risks due to ai deployment are job loss due to automation.

--> Privacy and security concern due to surveillance, profiling; socio economic inequality due to bias.

--> New age technologies developed in agile sprints, beta tested on early adopters.

--> Cross-border collaboration is needed to manage second and third order effects that ripple out of the innovation.

--> G.

--> Regulatory collaboration: as effects of emerging technologies permeate national boundaries.